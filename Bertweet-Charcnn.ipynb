{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10907190,"sourceType":"datasetVersion","datasetId":6779622}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom datasets import load_dataset\nimport pandas as pd\n\n\ntry:\n    tweet_dataset = load_dataset(\"SetFit/tweet_sentiment_extraction\", download_mode=\"force_redownload\")\nexcept Exception as e:\n    print(\"Error loading tweet dataset:\", e)\n\nemoji_dataset = pd.read_csv(\"/kaggle/input/data543/Emoji_Sentiment_Data_v1.0.csv\")\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\nbertweet_model = AutoModel.from_pretrained(\"vinai/bertweet-base\").to(device)\n\n\nclass CharCNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super(CharCNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.conv1 = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n        self.fc = nn.Linear(256, 128)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)\n        x = torch.relu(self.conv1(x))\n        x = torch.relu(self.conv2(x))\n        x = torch.max(x, dim=2).values\n        x = self.dropout(x)\n        return self.fc(x)\n\n\nclass HybridSentimentModel(nn.Module):\n    def __init__(self, bert_model, char_cnn, hidden_dim, output_dim):\n        super(HybridSentimentModel, self).__init__()\n        self.bert = bert_model\n        self.char_cnn = char_cnn\n        self.fc = nn.Linear(bert_model.config.hidden_size + 128, hidden_dim)\n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, text_input, emoji_input):\n        text_feat = self.bert(**text_input).pooler_output\n        emoji_feat = self.char_cnn(emoji_input)\n        combined = torch.cat((text_feat, emoji_feat), dim=1)\n        x = torch.relu(self.fc(combined))\n        x = self.dropout(x)\n        return self.out(x)\n\n\nvocab_size = len(emoji_dataset) + 1\nembed_dim = 64\nhidden_dim = 256\noutput_dim = 3\nchar_cnn = CharCNN(vocab_size, embed_dim, output_dim).to(device)\nmodel = HybridSentimentModel(bertweet_model, char_cnn, hidden_dim, output_dim).to(device)\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n\n\ndef encode_emoji(emoji_input):\n    emoji_indices = [emoji_dataset[emoji_dataset['Emoji'] == e].index[0] if e in emoji_dataset['Emoji'].values else len(emoji_dataset) for e in emoji_input]\n    if not emoji_indices:\n        return torch.zeros((1, 10), dtype=torch.long, device=device)\n    emoji_tensor = torch.tensor(emoji_indices, dtype=torch.long, device=device)\n    emoji_tensor = emoji_tensor.unsqueeze(0)\n    if emoji_tensor.size(1) < 10:\n        pad = torch.zeros((1, 10 - emoji_tensor.size(1)), dtype=torch.long, device=device)\n        emoji_tensor = torch.cat((emoji_tensor, pad), dim=1)\n    return emoji_tensor\n\n\ndef train(model, dataloader, criterion, optimizer, scheduler, epochs=3):\n    model.train()\n    all_preds = []\n    all_labels = []\n    epoch_losses = []\n    learning_rates = []\n\n    for epoch in range(epochs):\n        running_loss = 0\n        for batch in dataloader:\n            text_input, emoji_input, labels = batch\n            for key in text_input:\n                text_input[key] = text_input[key].squeeze(1).to(device)\n            emoji_input = emoji_input.squeeze(1).to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            output = model(text_input, emoji_input)\n            loss = criterion(output, labels)\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            all_preds.extend(torch.argmax(output, dim=1).tolist())\n            all_labels.extend(labels.tolist())\n\n        scheduler.step(running_loss / len(dataloader))\n\n        epoch_loss = running_loss / len(dataloader)\n        epoch_losses.append(epoch_loss)\n        learning_rates.append(optimizer.param_groups[0]['lr'])\n\n        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Learning Rate: {learning_rates[-1]:.6f}\")\n\n    \n    correct = sum(1 for p, l in zip(all_preds, all_labels) if p == l)\n    total = len(all_labels)\n    accuracy = correct / total * 100\n\n    print(f\"Final Accuracy: {accuracy:.2f}%\")\n\n\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, emojis, labels):\n        self.texts = texts\n        self.emojis = emojis\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = bertweet_tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n        emoji = encode_emoji(self.emojis[idx])\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return text, emoji, label\n\ntrain_texts = tweet_dataset['train']['text']\ntrain_emojis = [[c for c in text if c in emoji_dataset['Emoji'].values] for text in train_texts]\ntrain_labels = tweet_dataset['train']['label']\n\ntrain_dataset = SentimentDataset(train_texts, train_emojis, train_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n\ntrain(model, train_loader, criterion, optimizer, scheduler)\n\n\nwhile True:\n    user_input = input(\"Enter your text with emojis (type 'exit' to quit): \")\n    if user_input.lower() == 'exit':\n        break\n\n    user_text = ''.join(c for c in user_input if c.isalnum() or c.isspace())\n    user_emojis = [c for c in user_input if not c.isalnum() and not c.isspace()]\n\n    emoji_sample = encode_emoji(user_emojis)\n    text_sample = bertweet_tokenizer([user_text], padding='max_length', truncation=True, max_length=128, return_tensors='pt').to(device)\n\n    model.eval()\n    with torch.no_grad():\n        output = model(text_sample, emoji_sample)\n        predicted_label = torch.argmax(output, dim=1).item()\n\n    print(\"Predicted sentiment:\", [\"Negative\", \"Neutral\", \"Positive\"][predicted_label])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T16:00:15.347192Z","iopub.execute_input":"2025-03-12T16:00:15.347537Z","iopub.status.idle":"2025-03-12T16:40:04.905712Z","shell.execute_reply.started":"2025-03-12T16:00:15.347507Z","shell.execute_reply":"2025-03-12T16:40:04.904719Z"}},"outputs":[{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/3.93M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c9b3759fc34f72adb217eb216d4e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/503k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4475d54e3f084a99929c46b5db32e41f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/27481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c20829fc75140a0955e60b1c65dcdb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03f2b85723934c24a007b7497cfffeca"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Loss: 0.5797, Learning Rate: 0.000020\nEpoch 2, Loss: 0.4407, Learning Rate: 0.000020\nEpoch 3, Loss: 0.3474, Learning Rate: 0.000020\nFinal Accuracy: 82.02%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  I am glad that it happenedðŸ˜\n"},{"name":"stdout","text":"Predicted sentiment: Positive\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  I got kicked out badlyðŸ¤¬ðŸ¤¬\n"},{"name":"stdout","text":"Predicted sentiment: Negative\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  Somebody walked past meðŸ˜¶ðŸ˜¶ðŸ˜¶\n"},{"name":"stdout","text":"Predicted sentiment: Neutral\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  exit\n"}],"execution_count":3}]}