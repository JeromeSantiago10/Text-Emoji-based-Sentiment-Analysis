{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10907190,"sourceType":"datasetVersion","datasetId":6779622}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\nfrom datasets import load_dataset\nimport pandas as pd\n\n# Load datasets\ntry:\n    tweet_dataset = load_dataset(\"AdamLucek/twittersentiment-llama-3.1-405B-labels\", download_mode=\"force_redownload\")\nexcept Exception as e:\n    print(\"Error loading tweet dataset:\", e)\n\nemoji_dataset = pd.read_csv(\"/kaggle/input/data543/Emoji_Sentiment_Data_v1.0.csv\")\n\n# Load BERTweet tokenizer and model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\nbertweet_model = AutoModel.from_pretrained(\"vinai/bertweet-base\").to(device)\n\n# Character-Level CNN for emoji encoding\nclass CharCNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super(CharCNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.conv1 = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n        self.fc = nn.Linear(256, 128)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)\n        x = torch.relu(self.conv1(x))\n        x = torch.relu(self.conv2(x))\n        x = torch.max(x, dim=2).values\n        x = self.dropout(x)\n        return self.fc(x)\n\n# Combined Hybrid Model\nclass HybridSentimentModel(nn.Module):\n    def __init__(self, bert_model, char_cnn, hidden_dim, output_dim):\n        super(HybridSentimentModel, self).__init__()\n        self.bert = bert_model\n        self.char_cnn = char_cnn\n        self.fc = nn.Linear(bert_model.config.hidden_size + 128, hidden_dim)\n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, text_input, emoji_input):\n        text_feat = self.bert(**text_input).pooler_output\n        emoji_feat = self.char_cnn(emoji_input) * 2.0  # Prioritize emoji features\n        combined = torch.cat((text_feat, emoji_feat), dim=1)\n        x = torch.relu(self.fc(combined))\n        x = self.dropout(x)\n        return self.out(x)\n\n# Model Initialization\nvocab_size = len(emoji_dataset) + 1\nembed_dim = 64\nhidden_dim = 256\noutput_dim = 3\nchar_cnn = CharCNN(vocab_size, embed_dim, output_dim).to(device)\nmodel = HybridSentimentModel(bertweet_model, char_cnn, hidden_dim, output_dim).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n\n# Encode emoji input\ndef encode_emoji(emoji_input):\n    emoji_indices = [emoji_dataset[emoji_dataset['Emoji'] == e].index[0] if e in emoji_dataset['Emoji'].values else len(emoji_dataset) for e in emoji_input]\n    if not emoji_indices:\n        return torch.zeros((1, 10), dtype=torch.long, device=device)\n    emoji_tensor = torch.tensor(emoji_indices, dtype=torch.long, device=device)\n    emoji_tensor = emoji_tensor.unsqueeze(0)\n    if emoji_tensor.size(1) < 10:\n        pad = torch.zeros((1, 10 - emoji_tensor.size(1)), dtype=torch.long, device=device)\n        emoji_tensor = torch.cat((emoji_tensor, pad), dim=1)\n    return emoji_tensor\n\n# Enhanced sentiment weighting from emoji features\ndef get_emoji_sentiment_weight(emoji_input):\n    sentiment_weights = []\n    for e in emoji_input:\n        emoji_row = emoji_dataset[emoji_dataset['Emoji'] == e]\n        if not emoji_row.empty:\n            weights = emoji_row[['Negative', 'Neutral', 'Positive']].values[0]\n            sentiment_weights.append(weights)\n        else:\n            sentiment_weights.append([0, 0, 0])\n    if sentiment_weights:\n        return torch.tensor(sentiment_weights, dtype=torch.float32, device=device).mean(dim=0)\n    return torch.tensor([0, 0, 0], dtype=torch.float32, device=device)\n\n# Model training (example loop)\ndef train(model, dataloader, criterion, optimizer, scheduler, epochs=3):\n    model.train()\n    all_preds = []\n    all_labels = []\n    for epoch in range(epochs):\n        running_loss = 0\n        for batch in dataloader:\n            text_input, emoji_input, labels = batch\n            for key in text_input:\n                text_input[key] = text_input[key].squeeze(1).to(device)\n            emoji_input = emoji_input.squeeze(1).to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            output = model(text_input, emoji_input)\n\n            # Adjust loss using emoji sentiment weight\n            emoji_sentiment_weight = get_emoji_sentiment_weight(emoji_input)\n            loss = criterion(output, labels) - 0.1 * torch.sum(output * emoji_sentiment_weight)\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            all_preds.extend(torch.argmax(output, dim=1).tolist())\n            all_labels.extend(labels.tolist())\n\n        scheduler.step(running_loss / len(dataloader))\n\n        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader):.4f}\")\n\n    # Calculate metrics\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    precision = precision_score(all_labels, all_preds, average='weighted')\n    recall = recall_score(all_labels, all_preds, average='weighted')\n    accuracy = accuracy_score(all_labels, all_preds)\n\n    print(f\"\\nF1 Score: {f1:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n\n# Prepare training data\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, emojis, labels):\n        self.texts = texts\n        self.emojis = emojis\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = bertweet_tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n        emoji = encode_emoji(self.emojis[idx])\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return text, emoji, label\n\ntrain_texts = tweet_dataset['train']['text']\ntrain_emojis = [[c for c in text if c in emoji_dataset['Emoji'].values] for text in train_texts]\ntrain_labels = tweet_dataset['train']['label']\n\ntrain_dataset = SentimentDataset(train_texts, train_emojis, train_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n# Train the model\ntrain(model, train_loader, criterion, optimizer, scheduler)\n\n# User Input Loop\nwhile True:\n    user_input = input(\"Enter your text with emojis (type 'exit' to quit): \")\n    if user_input.lower() == 'exit':\n        break\n\n    user_text = ''.join(c for c in user_input if c.isalnum() or c.isspace())\n    user_emojis = [c for c in user_input if not c.isalnum() and not c.isspace()]\n\n    emoji_sample = encode_emoji(user_emojis)\n    text_sample = bertweet_tokenizer([user_text], padding='max_length', truncation=True, max_length=128, return_tensors='pt').to(device)\n\n    model.eval()\n    with torch.no_grad():\n        output = model(text_sample, emoji_sample)\n        predicted_label = torch.argmax(output, dim=1).item()\n\n    print(\"Predicted sentiment:\", [\"Negative\", \"Neutral\", \"Positive\"][predicted_label])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:01:06.019408Z","iopub.execute_input":"2025-03-06T18:01:06.019657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b12e68a8284d74b0b0803d100c3ae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/1.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ffeb06ba8142a388671fa8a81b8517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/282k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a11b1f1ee4546e9a5901b2fa0109cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4992 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8275c9026a14619a6125ad063b17611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da79e280ba754650a70875e707d5e250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aac98f52be96490f8cc47109171e1569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11728aa8bf23486c985fc926bf2363a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a665f7e9aec4bc2827b0dba95410a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd25a52104a8489392e1600d8b01e31d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a72a95135f4cbf935ce26da1878a5a"}},"metadata":{}},{"name":"stderr","text":"Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f58e6fb5d924d469cc28e57e1cb2604"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Loss: 0.8493\nEpoch 2, Loss: 0.5229\nEpoch 3, Loss: 0.4133\n\nF1 Score: 0.7565\nPrecision: 0.7635\nRecall: 0.7553\nAccuracy: 0.7553\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  I am happy😁😁😁\n"},{"name":"stdout","text":"Predicted sentiment: Positive\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  It was a very rough day😢😢😢\n"},{"name":"stdout","text":"Predicted sentiment: Negative\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your text with emojis (type 'exit' to quit):  someone was walking past me😶😶\n"},{"name":"stdout","text":"Predicted sentiment: Neutral\n","output_type":"stream"}],"execution_count":null}]}